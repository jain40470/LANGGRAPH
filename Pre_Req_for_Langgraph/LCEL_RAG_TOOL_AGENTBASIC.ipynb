{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = LANGCHAIN_TRACING_V2\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "\n",
    "GROQ_API_KEY  = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"model/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_google = ChatGoogleGenerativeAI(model = \"gemini-1.5-pro\" , temperature = 0 , convert_system_message_to_human=True)\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm_groq = ChatGroq(model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLE AI ASSISTANT / CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashjain/Desktop/LangGraph/venvLanggraph/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akashjain/Desktop/LangGraph/venvLanggraph/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking. How are you?\n",
      "Bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Hey what u want to ask else quit\")\n",
    "    if question == \"quit\":\n",
    "        print(\"Bye\")\n",
    "        break\n",
    "    else:\n",
    "        response = llm_google.invoke(question)\n",
    "        print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets also add memory thing in this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id : str) -> BaseChatMessageHistory :\n",
    "    if session_id not in chat_history:\n",
    "        chat_history[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_history[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {\"session_id\" : \"firstchat\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory = RunnableWithMessageHistory(llm_google , get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Akash! How can I help you today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke( (\"hello , i am akash\") , config=config ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Akash.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke( (\"hello , tell my name\") , config=config ).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "# Wikipedia Tool\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "#  WikipediaAPIWrapper :Utility class allows you to fetch summaries, full page content, and search results from Wikipedia.\n",
    "#  WikipediaQueryRun : tool wrapper that allows you to execute Wikipedia searches within LangChain.\n",
    "\n",
    "wiki_api_wrapper = WikipediaAPIWrapper()\n",
    "\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper = wiki_api_wrapper)\n",
    "\n",
    "print(wiki_tool.name)\n",
    "print(wiki_tool.description)\n",
    "print(wiki_tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval-augmented generation (RAG) is a technique that enables generative artificial intelligence (Gen AI) models to retrieve and incorporate new information. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to supplement information from its pre-existing training data. This allows LLMs to use domain-specific and/or updated information.  Use cases include providing chatbot access to internal company data or generating responses based on authoritative sources.\n",
      "RAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have led to real-world issues like chatbots inventing policies or lawyers citing nonexistent legal cases.\n",
      "By dynamically retrieving information, RAG enables AI to provide more accurate responses without frequent retraining. According to IBM, \"RAG also reduces the need for users to continuously train the model on new data and update its parameters as circumstances evolve. In this way, RAG can lower the computational and financial costs of running LLM-powered chatbots in an enterprise setting.\"\n",
      "Beyond efficiency gains, RAG also allows LLMs to include source references in their responses, enabling users to verify information by reviewing cited documents or original sources. This can provide greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\n",
      "\n",
      "\n",
      "\n",
      "Page: Milvus (vector database)\n",
      "Summary: Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service.\n",
      "Milvus is an open-source project under LF AI & Data Foundation distributed under the Apache License 2.0.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wiki_tool.run( { \"query\" : \"Langchain\" } ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube_search\n",
      "search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "#Youtube search tool\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "yt_tool = YouTubeSearchTool()\n",
    "\n",
    "print(yt_tool.name)\n",
    "print(yt_tool.description)\n",
    "print(yt_tool.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=Cs88FbH9sSU&pp=ygUHQ2FtcHVzeA%3D%3D', 'https://www.youtube.com/shorts/tFvfkiMXgIw']\n"
     ]
    }
   ],
   "source": [
    "print(yt_tool.run(\"Campusx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Mastering LangGraph: The Ultimate Guide to AI Systems, RAG ...',\n",
       "  'url': 'https://medium.com/@piyushkashyap045/mastering-langgraph-the-ultimate-guide-to-ai-systems-rag-agents-and-tools-ceca33090ef5',\n",
       "  'content': 'Tools can be customized or built from scratch using LangGraph’s framework.\\nHands-On: Setting Up LangGraph\\nTo get started with LangGraph, follow these steps:\\n1. Install Prerequisites\\nEnsure you have Python 3.9+ installed. Create a virtual environment and install the required libraries:\\npip install langchain chromadb google-generative-ai\\n2. Set Up Your Project\\nCreate a .env file to store API keys and other environment variables. Use a tool like dotenv to manage them: [...] from dotenv import load_dotenv\\nimport os\\nload_dotenv()\\nAPI_KEY = os.getenv(\"YOUR_API_KEY\")\\n3. Initialize LangGraph\\nSet up LangGraph with basic configurations:\\nfrom langchain.agents import initialize_agent\\nfrom langchain.tools import WikipediaQueryRunner\\nfrom langchain.llms import GoogleGenerativeAI\\nllm = GoogleGenerativeAI(api_key=API_KEY)\\nwiki_tool = WikipediaQueryRunner()\\nagent = initialize_agent(tools=[wiki_tool], llm=llm, agent=\"react-agent\")\\n4. Test the Agent [...] Conclusion\\nLangGraph is transforming how AI systems are built, making them more capable, adaptable, and user-friendly. By mastering its core components — AI assistants, RAG, agents, and tools — you can create cutting-edge applications that redefine interactivity and intelligence.\\nKey Takeaways:',\n",
       "  'score': 0.81489426},\n",
       " {'title': 'How to actually study Langgraph/agent? : r/LangChain - Reddit',\n",
       "  'url': 'https://www.reddit.com/r/LangChain/comments/1fnkdyy/how_to_actually_study_langgraphagent/',\n",
       "  'content': \"You can get started with a course on Deep Learning, titled 'AI Agents in Langgraph'. The course is produced by the official Langchain team.\",\n",
       "  'score': 0.6530611},\n",
       " {'title': 'LangGraph Tutorial: A Comprehensive Guide for Beginners',\n",
       "  'url': 'https://blog.futuresmart.ai/langgraph-tutorial-for-beginners',\n",
       "  'content': \"Getting Started with LangGraph\\nInstallation\\nTo get started with LangGraph, you will need to install it.\\nTo install LangGraph, open your terminal or command prompt and run the following command:\\npip install -U langgraph\\nThis command will download and install the latest version of LangGraph. The -U flag ensures you are getting the most up-to-date version.\\nCreating a Basic Chatbot in LangGraph\\nThis example is a good starting point for understanding the fundamental concepts of LangGraph. [...] If you want to build projects in LangChain, then I would recommend watching this YouTube Video: Mastering NL2SQL with LangChain and LangSmith\\nKey Concepts\\nGraph Structures\\nAt the heart of LangGraph's design lies a graph-based representation of the application's workflow. This graph comprises two primary elements: [...] Import Necessary Libraries: Begin by importing the required classes and modules from LangGraph and other relevant libraries.\\nfrom typing import Annotated\\n from typing_extensions import TypedDict\\n from langgraph.graph import StateGraph, START, END\\n from langgraph.graph.message import add_messages\",\n",
       "  'score': 0.60133666},\n",
       " {'title': 'LangGraph Simplified: Master Custom AI Agent Creation - YouTube',\n",
       "  'url': 'https://www.youtube.com/watch?v=R-o_a6dvzQM',\n",
       "  'content': 'Here’s a LangGraph tutorial that should put your mind at ease. There is significant interest in the LangGraph framework due to its customisability and integrations. However, many have found the core concepts to be quite complex. This video breaks down those core concepts in a friendly and digestible manner and provides you with a Python tutorial for a custom web search agent to help you concretise the theory.',\n",
       "  'score': 0.55623144},\n",
       " {'title': 'Mastering LangGraph: A Hands-On Guide to Building Complex ...',\n",
       "  'url': 'https://www.amazon.com/Mastering-LangGraph-Hands-Multi-Agent-Applications-ebook/dp/B0DKVB6RMY',\n",
       "  'content': \"By following the guidance in this book, you'll gain the confidence and skills needed to build cutting-edge LLM applications that can transform your business and drive innovation.\",\n",
       "  'score': 0.5446325}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For web Search\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "websearch_tool = TavilySearchResults()\n",
    "\n",
    "websearch_tool.invoke( {\"query\" : \"How to master Langgraph\" } )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Langchain agent (old version classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import load_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"wikipedia\"] , llm = llm_google)\n",
    "agent = initialize_agent( tool , llm_google , agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION , verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use wikipedia to find the population of India.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: population of India\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Demographics of India\n",
      "Summary: India is the most populous country in the world with one-sixth of the world's population.\n",
      "According to estimates from the United Nations (UN), India has overtaken China as the country with the largest population in the world, with a population of 1,425,775,850 at the end of April 2023.\n",
      "Between 1975 and 2010, the population doubled to 1.2 billion, reaching the billion mark in 2000. According to the UN's World Population dashboard, India's population now stands at slightly over 1.428 billion, edging past China's population of 1.425 billion people, as reported by the news agency Bloomberg. In 2015, India's population was predicted to reach 1.7 billion by 2050. In 2017 its population growth rate was 0.98%, ranking 112th in the world; in contrast, from 1972 to 1983, India's population grew by an annual rate of 2.3%.\n",
      "In 2023, the median age of an Indian was 29.5 years, compared to 39.8 for China and 49.5 for Japan; and, by 2030; India's dependency ratio will be just over 0.4. However, the number of children in India peaked more than a decade ago and is now falling. The number of children under the age of five peaked in 2007, and since then the number has been falling. The number of Indians under 15 years old peaked slightly later (in 2011) and is now also declining.\n",
      "India has many ethnic groups, and every major region is represented, as are four major families of languages (Indo-European, Dravidian, Austroasiatic and Sino-Tibetan languages) as well as two language isolates: the Nihali language, spoken in parts of Maharashtra, and the Burushaski language, spoken in parts of Jammu and Kashmir. 1,000,000 people in India are Anglo-Indians and between 25,000 and 70,000 people are  Siddhis,who are descendants of Bantu slaves brought by Arabs, Persians and Portuguese to the western coast of India during the  Middle Ages and the colonial period. They represent over 0.1% of the total population of India. Overall, only the continent of Africa exceeds the linguistic, genetic and cultural diversity of the nation of India.\n",
      "The sex ratio was 944 females for 1000 males in 2016, and 940 per 1000 in 2011. This ratio has been showing an upwards trend for the last two decades after a continuous decline in the 20th century.\n",
      "\n",
      "Page: List of states and union territories of India by population\n",
      "Summary: India is a union consisting of 28 states and 8 union territories. As of 2024, with an estimated population of 1.40 Caror, India is the world's most populous country. India occupies 2.4% of the world's area and is home to 17.5% of the world's population. The Indo-Gangetic Plain has one of the world's biggest stretches of fertile not-deep alluvium and are among the most densely populated areas of the world. The eastern and western coastal regions of Deccan Plateau are also densely populated regions of India. The Thar Desert in western Rajasthan is one of the most densely populated deserts in the world. The northern and north-eastern states along the Himalayas contain cold arid deserts with fertile valleys. These states have relatively low population density due to indomitable physical barriers.\n",
      "\n",
      "\n",
      "\n",
      "Page: List of cities in India by population\n",
      "Summary: This is a list of the most populous cities in India. Cities are a type of sub-administrative unit and are defined by the Ministry of Home Affairs. In some cases, cities are bifurcated into municipalities, which can lead to cities being included within other cities. This list is based on the Census of India using data from the 2001 census of India and the 2011 census of India.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have enough information to answer the question.  The UN estimates India's population to be over 1.428 billion.\n",
      "\n",
      "Final Answer: India's population is estimated to be over 1.428 billion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"India's population is estimated to be over 1.428 billion.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"tell me india's population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLanggraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
